{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\n\nimport torch\nimport torch.nn as nn\nfrom sklearn.metrics import precision_recall_fscore_support, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom torch import optim\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom tqdm.notebook import tqdm\nfrom transformers import AutoModel, AutoTokenizer\n#display options\npd.set_option('display.max_colwidth', None)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T07:53:25.628267Z","iopub.execute_input":"2022-04-26T07:53:25.629003Z","iopub.status.idle":"2022-04-26T07:53:28.238Z","shell.execute_reply.started":"2022-04-26T07:53:25.628815Z","shell.execute_reply":"2022-04-26T07:53:28.237243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hyperparameters = {\n    \"max_length\": 416,\n    \"padding\": \"max_length\",\n    \"return_offsets_mapping\": True,\n    \"truncation\": \"only_second\",\n    \"debug\": False,\n    \"model_name\": (\"../input/layoutlm/BiomedNLP-PubMedBERT\"\n                   \"-base-uncased-abstract-fulltext\"),\n    \"dropout\": 0.2,\n    \"encoder_lr\": 1e-5,\n    \"decoder_lr\": 1e-5,\n    \"weight_decay\": 0.01,\n    \"betas\": (0.9, 0.999),\n    \"lr\": 1e-5,\n    \n    \"seed\": 1268,\n    \"test_batch_size\": 8,\n    \"epochs\": 6,\n    \n    \"apex\": True,\n    \"eps\": 1e-6,\n    \n    \"n_fold\": 5,\n    \"trn_fold\": [1, 2, 3, 4, 5],\n    \n    \"precompute_tokens\":True\n}\nif hyperparameters['debug']:\n    hyperparameters['epochs'] = 2\n    hyperparameters['trn_fold'] = [1,2]","metadata":{"execution":{"iopub.status.busy":"2022-04-26T07:53:28.240078Z","iopub.execute_input":"2022-04-26T07:53:28.240314Z","iopub.status.idle":"2022-04-26T07:53:28.246593Z","shell.execute_reply.started":"2022-04-26T07:53:28.240284Z","shell.execute_reply":"2022-04-26T07:53:28.245853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_location_predictions(preds, offset_mapping, sequence_ids, test=False):\n    all_predictions = []\n    for pred, offsets, seq_ids in zip(preds, offset_mapping, sequence_ids):\n        if not test:\n            pred = 1 / (1 + np.exp(-pred))\n        else:\n            pass\n        start_idx = None\n        end_idx = None\n        current_preds = []\n        for pred, offset, seq_id in zip(pred, offsets, seq_ids):\n            if seq_id is None or seq_id == 0:\n                continue\n\n            if pred > 0.5:\n                if start_idx is None:\n                    start_idx = offset[0]\n                end_idx = offset[1]\n            elif start_idx is not None:\n                #增加if语句筛选0 0的状况\n                if test:\n                    if start_idx==0 and end_idx==0:\n                        start_idx = None\n                        continue\n                    current_preds.append(f\"{start_idx} {end_idx}\")\n                else:\n                    current_preds.append((start_idx, end_idx))\n                start_idx = None\n        if test:\n            all_predictions.append(\"; \".join(current_preds))\n        else:\n            all_predictions.append(current_preds)\n            \n    return all_predictions","metadata":{"execution":{"iopub.status.busy":"2022-04-26T07:53:28.24795Z","iopub.execute_input":"2022-04-26T07:53:28.248413Z","iopub.status.idle":"2022-04-26T07:53:28.26026Z","shell.execute_reply.started":"2022-04-26T07:53:28.24836Z","shell.execute_reply":"2022-04-26T07:53:28.259467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#数据导入\nBASE_URL = \"../input/nbme-score-clinical-patient-notes\"\nTRAIN_URL = \"../input/pubmedbert\"\nimport re\ndef process_feature_text(text):\n    text = re.sub('I-year', '1-year', text)\n    text = re.sub('-OR-', \" or \", text)\n    text = re.sub('-', ' ', text)\n    return text\ndef clean_spaces(text):\n    text = re.sub('\\n', ' ', text)\n    text = re.sub('\\t', ' ', text)\n    text = re.sub('\\r', ' ', text)\n    return text\n\ndef create_test_df():\n    feats = pd.read_csv(f\"{BASE_URL}/features.csv\")\n    notes = pd.read_csv(f\"{BASE_URL}/patient_notes.csv\")\n    test = pd.read_csv(f\"{BASE_URL}/test.csv\")\n\n    merged = test.merge(notes, how=\"left\")\n    merged = merged.merge(feats, how=\"left\")\n\n#     def process_feature_text(text):\n#         return text.replace(\"-OR-\", \";-\").replace(\"-\", \" \").replace(\"I-year\", \"1-year\")\n    \n#     merged[\"feature_text\"] = [process_feature_text(x) for x in merged[\"feature_text\"]]\n    merged['pn_history'] = merged['pn_history'].apply(lambda x: x.strip())\n    merged['feature_text'] = merged['feature_text'].apply(process_feature_text)\n    merged['feature_text'] = merged['feature_text'].apply(clean_spaces)\n    merged[\"clean_text\"] = merged[\"pn_history\"].apply(clean_spaces)\n    \n    return merged\n\ntest_df = create_test_df()\n\ntokenizer = AutoTokenizer.from_pretrained(hyperparameters['model_name'])\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n#Dataset类\nclass SubmissionDataset(Dataset):\n    def __init__(self, data, tokenizer, config):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.config = config\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        example = self.data.loc[idx]\n        tokenized = self.tokenizer(\n            example[\"feature_text\"],\n            #example[\"pn_history\"],\n            example['clean_text'],\n            truncation = self.config['truncation'],\n            max_length = self.config['max_length'],\n            padding = self.config['padding'],\n            return_offsets_mapping = self.config['return_offsets_mapping']\n        )\n        tokenized[\"sequence_ids\"] = tokenized.sequence_ids()\n\n        input_ids = np.array(tokenized[\"input_ids\"])\n        attention_mask = np.array(tokenized[\"attention_mask\"])\n        token_type_ids = np.array(tokenized[\"token_type_ids\"])\n        offset_mapping = np.array(tokenized[\"offset_mapping\"])\n        sequence_ids = np.array(tokenized[\"sequence_ids\"]).astype(\"float16\")\n\n        return input_ids, attention_mask, token_type_ids, offset_mapping, sequence_ids\n\n\n\n\nsubmission_data = SubmissionDataset(test_df, tokenizer, hyperparameters)\nsubmission_dataloader = DataLoader(submission_data,\n                                   batch_size=hyperparameters['test_batch_size'],\n                                   pin_memory=True,\n                                   shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T07:53:28.261736Z","iopub.execute_input":"2022-04-26T07:53:28.26216Z","iopub.status.idle":"2022-04-26T07:53:29.094688Z","shell.execute_reply.started":"2022-04-26T07:53:28.262119Z","shell.execute_reply":"2022-04-26T07:53:29.093879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass CustomModel(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.model = AutoModel.from_pretrained(config['model_name']) \n        self.dropout = nn.Dropout(p=config['dropout'])\n        self.config = config\n        self.fc1 = nn.Linear(768, 512)\n        self.fc2 = nn.Linear(512, 512)\n        self.fc3 = nn.Linear(512, 1)\n        \n\n    def forward(self, input_ids, attention_mask, token_type_ids):\n        outputs = self.model(input_ids=input_ids,\n                            attention_mask=attention_mask,\n                            token_type_ids=token_type_ids)\n        logits = F.relu(self.fc1(outputs[0]))\n        logits = F.relu(self.fc2(self.dropout(logits)))\n        logits = self.fc3(self.dropout(logits)).squeeze(-1)\n        return logits\n    \nmodel = CustomModel(hyperparameters).to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T07:53:29.096065Z","iopub.execute_input":"2022-04-26T07:53:29.096301Z","iopub.status.idle":"2022-04-26T07:53:37.833002Z","shell.execute_reply.started":"2022-04-26T07:53:29.09627Z","shell.execute_reply":"2022-04-26T07:53:37.832274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n#准备分折预测\npredictions = []\nfor fold in hyperparameters['trn_fold']:\n    model = CustomModel(hyperparameters).to(DEVICE)\n    #梯度置为0\n    model.zero_grad()\n    model.load_state_dict(torch.load(f\"{TRAIN_URL}/nbme_pubmed_bert_fold{fold}.pth\"))\n    model.eval()\n    #初始化指标容器\n    preds = []\n    offsets = []\n    seq_ids = []\n#     logits_container = []\n    with torch.no_grad():\n        for batch in tqdm(submission_dataloader):\n            input_ids = batch[0].to(DEVICE)\n            attention_mask = batch[1].to(DEVICE)\n            token_type_ids = batch[2].to(DEVICE)\n            offset_mapping = batch[3]\n            sequence_ids = batch[4]\n            logits = model(input_ids, attention_mask, token_type_ids)\n    #         logits_container.append(logits)\n            preds.append(logits.sigmoid().detach().cpu().numpy())\n            offsets.append(offset_mapping.numpy())\n            seq_ids.append(sequence_ids.numpy())\n    \n    preds = np.concatenate(preds, axis=0)\n    predictions.append(preds)\n    offsets = np.concatenate(offsets, axis=0)\n    seq_ids = np.concatenate(seq_ids, axis=0)\n    \n    del model,preds; gc.collect()\n    torch.cuda.empty_cache()\n#五折总输出的平均\npredictions = np.mean(predictions,axis=0)\n\n#输出\nlocation_preds = get_location_predictions(predictions, offsets, seq_ids, test=True)\ntest_df[\"location\"] = location_preds\ntest_df[[\"id\", \"location\"]].to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T07:53:37.834401Z","iopub.execute_input":"2022-04-26T07:53:37.834677Z","iopub.status.idle":"2022-04-26T07:54:03.529035Z","shell.execute_reply.started":"2022-04-26T07:53:37.834643Z","shell.execute_reply":"2022-04-26T07:54:03.528036Z"},"trusted":true},"execution_count":null,"outputs":[]}]}